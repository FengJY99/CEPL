***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/EFF_Prompts/vit_b16_cepl.yaml
dataset_config_file: configs/datasets/eurosat.yaml
eval_only: False
head: 
load_epoch: None
model_dir: 
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'TRAINER.EFF_PROMPTS.N_CTX', '32', 'TRAINER.EFF_PROMPTS.CL', 'EFF_Prompts', 'TRAINER.EFF_PROMPTS.PREC', 'fp32', 'TRAINER.EFF_PROMPTS.w1', '1.0', 'TRAINER.EFF_PROMPTS.w2', '8.0', 'OPTIM.MAX_EPOCH', '100']
output_dir: /CEPL_outputs/few_shots/CEPL_L_16shot/eurosat/vit_b16_cepl_16shots/seed2
resume: 
root: /home/DATA
seed: 2
source_domains: None
target_domains: None
trainer: EFF_Prompts_5
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 1
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 1
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: EuroSAT
  NUM_LABELED: -1
  NUM_SHOTS: 16
  ROOT: /home/DATA
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 100
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: /CEPL_outputs/few_shots/CEPL_L_16shot/eurosat/vit_b16_cepl_16shots/seed2
RESUME: 
SEED: 2
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 100
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  CEPL:
    ALPHA: 1.0
    CL: EFF_Prompts
    CTX_INIT: 
    N_CTX: 32
    PREC: fp32
    w1: 1.0
    w2: 8.0
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  EFF_PROMPTS:
    ALPHA: 1.0
    CL: EFF_Prompts
    CTX_INIT: 
    N_CTX: 32
    PREC: fp32
    w1: 1.0
    w2: 8.0
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: EFF_Prompts_5
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Loading trainer: EFF_Prompts_5
Loading dataset: EuroSAT
Reading split from /home/DATA/eurosat/split_zhou_EuroSAT.json
Loading preprocessed few-shot data from /home/DATA/eurosat/split_fewshot/shot_16-seed_2.pkl
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------
Dataset    EuroSAT
# classes  10
# train_x  160
# val      40
# test     8,100
---------  -------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X."
Number of context words (tokens): 32
Building text dataset per class...


Using linear_head: no norm scale, with bias. And lr should be 0.002 -> 1e-5 !
Turning off gradients in both the image and the text encoder
Parameters to be updated: {'image_encoder.transformer.resblocks.3.attn.lora_Q_B', 'image_encoder.transformer.resblocks.10.mlp.c_fc.linear.lora_B', 'image_encoder.transformer.resblocks.8.attn.lora_V_A', 'text_encoder.transformer.resblocks.7.mlp.c_proj.linear.lora_A', 'image_encoder.transformer.resblocks.7.attn.lora_out_proj_B', 'text_encoder.transformer.resblocks.11.attn.lora_Q_A', 'image_encoder.transformer.resblocks.7.mlp.c_fc.linear.lora_A', 'text_encoder.transformer.resblocks.5.attn.lora_Q_A', 'image_encoder.transformer.resblocks.10.attn.lora_out_proj_A', 'text_encoder.transformer.resblocks.10.attn.lora_Q_A', 'text_encoder.transformer.resblocks.6.attn.lora_Q_B', 'text_encoder.transformer.resblocks.3.mlp.c_fc.linear.lora_A', 'text_encoder.transformer.resblocks.10.mlp.c_fc.linear.lora_A', 'image_encoder.transformer.resblocks.10.attn.lora_K_A', 'text_encoder.transformer.resblocks.3.attn.lora_V_B', 'text_encoder.transformer.resblocks.8.mlp.c_fc.linear.lora_A', 'text_encoder.transformer.resblocks.8.attn.lora_V_B', 'image_encoder.transformer.resblocks.6.mlp.c_proj.linear.lora_B', 'text_encoder.transformer.resblocks.7.attn.lora_out_proj_B', 'text_encoder.transformer.resblocks.8.attn.lora_Q_A', 'text_encoder.transformer.resblocks.10.mlp.c_fc.linear.lora_B', 'prompt_learner.meta_net.linear1.bias', 'image_encoder.transformer.resblocks.8.attn.lora_out_proj_B', 'image_encoder.transformer.resblocks.7.mlp.c_fc.linear.lora_B', 'text_encoder.transformer.resblocks.7.attn.lora_V_B', 'text_encoder.transformer.resblocks.11.attn.lora_K_A', 'text_encoder.transformer.resblocks.9.attn.lora_out_proj_B', 'image_encoder.transformer.resblocks.11.attn.lora_out_proj_A', 'text_encoder.transformer.resblocks.6.mlp.c_fc.linear.lora_A', 'trans_block.atten.attn.in_proj_weight', 'text_encoder.transformer.resblocks.6.attn.lora_K_A', 'image_encoder.transformer.resblocks.7.attn.lora_out_proj_A', 'trans_block.atten.ln_1.weight', 'text_encoder.transformer.resblocks.4.attn.lora_K_A', 'text_encoder.transformer.resblocks.5.mlp.c_fc.linear.lora_B', 'text_encoder.transformer.resblocks.8.attn.lora_Q_B', 'image_encoder.transformer.resblocks.11.attn.lora_Q_B', 'image_encoder.transformer.resblocks.11.mlp.c_proj.linear.lora_A', 'text_encoder.transformer.resblocks.4.attn.lora_Q_A', 'text_encoder.transformer.resblocks.6.mlp.c_proj.linear.lora_A', 'text_encoder.transformer.resblocks.3.attn.lora_Q_B', 'image_encoder.transformer.resblocks.4.attn.lora_K_A', 'text_encoder.transformer.resblocks.10.attn.lora_out_proj_B', 'trans_block.atten.attn.out_proj.weight', 'image_encoder.transformer.resblocks.8.mlp.c_fc.linear.lora_B', 'text_encoder.transformer.resblocks.3.attn.lora_out_proj_B', 'text_encoder.transformer.resblocks.6.attn.lora_K_B', 'image_encoder.transformer.resblocks.11.attn.lora_V_B', 'image_encoder.transformer.resblocks.5.attn.lora_out_proj_A', 'text_encoder.transformer.resblocks.3.attn.lora_out_proj_A', 'image_encoder.transformer.resblocks.10.mlp.c_fc.linear.lora_A', 'image_encoder.transformer.resblocks.11.attn.lora_Q_A', 'text_encoder.transformer.resblocks.4.mlp.c_fc.linear.lora_B', 'text_encoder.transformer.resblocks.6.attn.lora_V_B', 'text_encoder.transformer.resblocks.7.attn.lora_K_B', 'image_encoder.transformer.resblocks.4.attn.lora_Q_B', 'image_encoder.transformer.resblocks.11.mlp.c_proj.linear.lora_B', 'text_encoder.transformer.resblocks.5.mlp.c_fc.linear.lora_A', 'text_encoder.transformer.resblocks.6.mlp.c_proj.linear.lora_B', 'text_encoder.transformer.resblocks.10.attn.lora_K_B', 'image_encoder.transformer.resblocks.5.attn.lora_Q_B', 'text_encoder.transformer.resblocks.4.attn.lora_Q_B', 'image_encoder.transformer.resblocks.3.mlp.c_fc.linear.lora_B', 'text_encoder.transformer.resblocks.9.mlp.c_proj.linear.lora_A', 'text_encoder.transformer.resblocks.11.mlp.c_fc.linear.lora_B', 'image_encoder.transformer.resblocks.3.attn.lora_V_B', 'image_encoder.transformer.resblocks.9.attn.lora_K_A', 'image_encoder.transformer.resblocks.9.attn.lora_out_proj_B', 'text_encoder.transformer.resblocks.11.mlp.c_proj.linear.lora_B', 'image_encoder.transformer.resblocks.4.attn.lora_Q_A', 'image_encoder.transformer.resblocks.10.attn.lora_V_B', 'image_encoder.transformer.resblocks.5.attn.lora_out_proj_B', 'image_encoder.transformer.resblocks.11.mlp.c_fc.linear.lora_B', 'trans_block.proj', 'text_encoder.transformer.resblocks.6.attn.lora_Q_A', 'image_encoder.transformer.resblocks.5.attn.lora_V_A', 'trans_block.atten.ln_1.bias', 'image_encoder.transformer.resblocks.3.attn.lora_out_proj_B', 'image_encoder.transformer.resblocks.7.attn.lora_K_B', 'image_encoder.transformer.resblocks.5.mlp.c_proj.linear.lora_A', 'image_encoder.transformer.resblocks.3.mlp.c_proj.linear.lora_A', 'image_encoder.transformer.resblocks.5.attn.lora_K_B', 'image_encoder.transformer.resblocks.11.mlp.c_fc.linear.lora_A', 'text_encoder.transformer.resblocks.5.mlp.c_proj.linear.lora_B', 'text_encoder.transformer.resblocks.9.attn.lora_K_A', 'image_encoder.transformer.resblocks.7.attn.lora_K_A', 'image_encoder.transformer.resblocks.8.attn.lora_V_B', 'text_encoder.transformer.resblocks.8.attn.lora_K_A', 'text_encoder.transformer.resblocks.11.attn.lora_V_B', 'image_encoder.transformer.resblocks.4.mlp.c_proj.linear.lora_B', 'image_encoder.transformer.resblocks.10.attn.lora_K_B', 'text_encoder.transformer.resblocks.8.mlp.c_proj.linear.lora_A', 'text_encoder.transformer.resblocks.10.attn.lora_K_A', 'text_encoder.transformer.resblocks.9.attn.lora_V_B', 'image_encoder.transformer.resblocks.4.mlp.c_fc.linear.lora_B', 'text_encoder.transformer.resblocks.11.attn.lora_K_B', 'text_encoder.transformer.resblocks.5.attn.lora_out_proj_A', 'image_encoder.transformer.resblocks.4.attn.lora_out_proj_B', 'text_encoder.transformer.resblocks.4.mlp.c_proj.linear.lora_B', 'image_encoder.transformer.resblocks.6.mlp.c_fc.linear.lora_A', 'cls_head.weight', 'image_encoder.transformer.resblocks.6.attn.lora_K_A', 'image_encoder.transformer.resblocks.6.attn.lora_out_proj_B', 'image_encoder.transformer.resblocks.7.attn.lora_Q_B', 'image_encoder.transformer.resblocks.11.attn.lora_K_A', 'text_encoder.transformer.resblocks.9.attn.lora_out_proj_A', 'image_encoder.transformer.resblocks.3.attn.lora_V_A', 'image_encoder.transformer.resblocks.3.mlp.c_proj.linear.lora_B', 'text_encoder.transformer.resblocks.9.mlp.c_fc.linear.lora_A', 'text_encoder.transformer.resblocks.10.mlp.c_proj.linear.lora_A', 'image_encoder.transformer.resblocks.6.mlp.c_proj.linear.lora_A', 'image_encoder.transformer.resblocks.6.attn.lora_out_proj_A', 'image_encoder.transformer.resblocks.10.attn.lora_out_proj_B', 'image_encoder.transformer.resblocks.9.attn.lora_Q_A', 'text_encoder.transformer.resblocks.7.mlp.c_fc.linear.lora_A', 'text_encoder.transformer.resblocks.11.attn.lora_V_A', 'image_encoder.transformer.resblocks.5.mlp.c_fc.linear.lora_A', 'trans_block.atten.ln_2.weight', 'prompt_learner.meta_net.linear2.bias', 'text_encoder.transformer.resblocks.4.attn.lora_V_A', 'image_encoder.transformer.resblocks.11.attn.lora_out_proj_B', 'image_encoder.transformer.resblocks.9.mlp.c_fc.linear.lora_B', 'image_encoder.transformer.resblocks.5.attn.lora_V_B', 'image_encoder.transformer.resblocks.10.mlp.c_proj.linear.lora_A', 'image_encoder.transformer.resblocks.6.attn.lora_V_B', 'text_encoder.transformer.resblocks.7.attn.lora_V_A', 'image_encoder.transformer.resblocks.5.mlp.c_proj.linear.lora_B', 'image_encoder.transformer.resblocks.7.mlp.c_proj.linear.lora_B', 'text_encoder.transformer.resblocks.9.attn.lora_Q_A', 'image_encoder.transformer.resblocks.4.attn.lora_out_proj_A', 'text_encoder.transformer.resblocks.9.attn.lora_Q_B', 'image_encoder.transformer.resblocks.6.attn.lora_V_A', 'image_encoder.transformer.resblocks.6.attn.lora_Q_B', 'image_encoder.transformer.resblocks.3.attn.lora_Q_A', 'text_encoder.transformer.resblocks.7.mlp.c_proj.linear.lora_B', 'text_encoder.transformer.resblocks.6.attn.lora_out_proj_A', 'text_encoder.transformer.resblocks.8.mlp.c_fc.linear.lora_B', 'text_encoder.transformer.resblocks.9.mlp.c_fc.linear.lora_B', 'trans_block.atten.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.3.mlp.c_fc.linear.lora_B', 'text_encoder.transformer.resblocks.7.attn.lora_out_proj_A', 'text_encoder.transformer.resblocks.7.mlp.c_fc.linear.lora_B', 'image_encoder.transformer.resblocks.10.attn.lora_Q_B', 'image_encoder.transformer.resblocks.10.attn.lora_V_A', 'text_encoder.transformer.resblocks.4.attn.lora_out_proj_B', 'text_encoder.transformer.resblocks.8.attn.lora_out_proj_A', 'image_encoder.transformer.resblocks.10.attn.lora_Q_A', 'cls_head.bias', 'text_encoder.transformer.resblocks.11.mlp.c_proj.linear.lora_A', 'text_encoder.transformer.resblocks.4.attn.lora_V_B', 'text_encoder.transformer.resblocks.7.attn.lora_K_A', 'image_encoder.transformer.resblocks.4.attn.lora_K_B', 'trans_block.atten.ln_2.bias', 'text_encoder.transformer.resblocks.10.mlp.c_proj.linear.lora_B', 'image_encoder.transformer.resblocks.5.attn.lora_Q_A', 'text_encoder.transformer.resblocks.11.attn.lora_out_proj_A', 'text_encoder.transformer.resblocks.10.attn.lora_Q_B', 'image_encoder.transformer.resblocks.4.mlp.c_fc.linear.lora_A', 'image_encoder.transformer.resblocks.6.attn.lora_Q_A', 'image_encoder.transformer.resblocks.8.attn.lora_Q_A', 'image_encoder.transformer.resblocks.9.attn.lora_V_B', 'image_encoder.transformer.resblocks.9.mlp.c_fc.linear.lora_A', 'text_encoder.transformer.resblocks.3.mlp.c_proj.linear.lora_A', 'text_encoder.transformer.resblocks.8.attn.lora_V_A', 'image_encoder.transformer.resblocks.9.attn.lora_Q_B', 'text_encoder.transformer.resblocks.9.attn.lora_K_B', 'image_encoder.transformer.resblocks.3.attn.lora_K_A', 'text_encoder.transformer.resblocks.11.mlp.c_fc.linear.lora_A', 'text_encoder.transformer.resblocks.5.attn.lora_V_B', 'trans_block.atten.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.3.mlp.c_proj.linear.lora_B', 'image_encoder.transformer.resblocks.8.mlp.c_fc.linear.lora_A', 'image_encoder.transformer.resblocks.8.mlp.c_proj.linear.lora_A', 'image_encoder.transformer.resblocks.11.attn.lora_K_B', 'image_encoder.transformer.resblocks.8.attn.lora_Q_B', 'image_encoder.transformer.resblocks.3.attn.lora_out_proj_A', 'trans_block.atten.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.5.mlp.c_fc.linear.lora_B', 'trans_block.atten.attn.in_proj_bias', 'prompt_learner.ctx', 'text_encoder.transformer.resblocks.8.attn.lora_out_proj_B', 'text_encoder.transformer.resblocks.3.attn.lora_Q_A', 'embedding_weight_t', 'image_encoder.transformer.resblocks.3.attn.lora_K_B', 'text_encoder.transformer.resblocks.3.attn.lora_V_A', 'text_encoder.transformer.resblocks.5.attn.lora_out_proj_B', 'image_encoder.transformer.resblocks.10.mlp.c_proj.linear.lora_B', 'text_encoder.transformer.resblocks.4.attn.lora_K_B', 'text_encoder.transformer.resblocks.6.attn.lora_V_A', 'image_encoder.transformer.resblocks.4.attn.lora_V_B', 'text_encoder.transformer.resblocks.6.mlp.c_fc.linear.lora_B', 'image_encoder.transformer.resblocks.5.attn.lora_K_A', 'text_encoder.transformer.resblocks.11.attn.lora_Q_B', 'image_encoder.transformer.resblocks.8.attn.lora_K_B', 'text_encoder.transformer.resblocks.8.attn.lora_K_B', 'image_encoder.transformer.resblocks.6.attn.lora_K_B', 'text_encoder.transformer.resblocks.7.attn.lora_Q_A', 'image_encoder.transformer.resblocks.7.attn.lora_Q_A', 'text_encoder.transformer.resblocks.9.attn.lora_V_A', 'image_encoder.transformer.resblocks.9.mlp.c_proj.linear.lora_B', 'text_encoder.transformer.resblocks.4.mlp.c_proj.linear.lora_A', 'prompt_learner.meta_net.linear2.weight', 'image_encoder.transformer.resblocks.6.mlp.c_fc.linear.lora_B', 'image_encoder.transformer.resblocks.9.mlp.c_proj.linear.lora_A', 'text_encoder.transformer.resblocks.5.attn.lora_K_B', 'text_encoder.transformer.resblocks.8.mlp.c_proj.linear.lora_B', 'text_encoder.transformer.resblocks.5.mlp.c_proj.linear.lora_A', 'image_encoder.transformer.resblocks.7.attn.lora_V_B', 'image_encoder.transformer.resblocks.4.attn.lora_V_A', 'trans_block.atten.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.7.attn.lora_Q_B', 'text_encoder.transformer.resblocks.3.attn.lora_K_A', 'image_encoder.transformer.resblocks.8.attn.lora_out_proj_A', 'trans_block.atten.attn.out_proj.bias', 'text_encoder.transformer.resblocks.5.attn.lora_K_A', 'image_encoder.transformer.resblocks.8.attn.lora_K_A', 'text_encoder.transformer.resblocks.5.attn.lora_V_A', 'image_encoder.transformer.resblocks.7.attn.lora_V_A', 'image_encoder.transformer.resblocks.9.attn.lora_V_A', 'trans_block.ln_post.bias', 'text_encoder.transformer.resblocks.10.attn.lora_out_proj_A', 'text_encoder.transformer.resblocks.10.attn.lora_V_B', 'text_encoder.transformer.resblocks.10.attn.lora_V_A', 'text_encoder.transformer.resblocks.5.attn.lora_Q_B', 'text_encoder.transformer.resblocks.11.attn.lora_out_proj_B', 'text_encoder.transformer.resblocks.4.mlp.c_fc.linear.lora_A', 'text_encoder.transformer.resblocks.9.mlp.c_proj.linear.lora_B', 'image_encoder.transformer.resblocks.9.attn.lora_K_B', 'text_encoder.transformer.resblocks.6.attn.lora_out_proj_B', 'image_encoder.transformer.resblocks.11.attn.lora_V_A', 'text_encoder.transformer.resblocks.4.attn.lora_out_proj_A', 'trans_block.ln_post.weight', 'image_encoder.transformer.resblocks.7.mlp.c_proj.linear.lora_A', 'image_encoder.transformer.resblocks.8.mlp.c_proj.linear.lora_B', 'image_encoder.transformer.resblocks.9.attn.lora_out_proj_A', 'text_encoder.transformer.resblocks.3.attn.lora_K_B', 'image_encoder.transformer.resblocks.3.mlp.c_fc.linear.lora_A', 'image_encoder.transformer.resblocks.4.mlp.c_proj.linear.lora_A', 'prompt_learner.meta_net.linear1.weight'}
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=/CEPL_outputs/few_shots/CEPL_L_16shot/eurosat/vit_b16_cepl_16shots/seed2/tensorboard)
epoch [1/100] batch [100/160] time 0.099 (0.107) data 0.000 (0.004) loss 8.4042 (11.1284) cls_loss 1.8171 (4.3216) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.4674 (0.4924) contrast_loss 2.1712 (2.1906) lr 1.0000e-05 eta 0:28:18
epoch [2/100] batch [100/160] time 0.095 (0.099) data 0.000 (0.003) loss 18.9054 (22.8600) cls_loss 13.7354 (17.2335) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.2774 (0.3442) contrast_loss 2.2741 (2.1959) lr 2.0000e-03 eta 0:26:05
epoch [3/100] batch [100/160] time 0.099 (0.099) data 0.000 (0.002) loss 9.3593 (8.5344) cls_loss 5.3252 (4.4806) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.1388 (0.1501) contrast_loss 2.2470 (2.1759) lr 1.9995e-03 eta 0:25:39
epoch [4/100] batch [100/160] time 0.094 (0.099) data 0.000 (0.002) loss 7.2721 (5.5506) cls_loss 3.4997 (2.0462) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.1165 (0.0914) contrast_loss 2.1632 (2.0966) lr 1.9980e-03 eta 0:25:22
epoch [5/100] batch [100/160] time 0.097 (0.099) data 0.000 (0.002) loss 4.1306 (4.9344) cls_loss 0.8968 (1.5720) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0787 (0.0755) contrast_loss 1.9275 (2.0817) lr 1.9956e-03 eta 0:25:06
epoch [6/100] batch [100/160] time 0.097 (0.099) data 0.000 (0.002) loss 4.6423 (4.6869) cls_loss 1.5673 (1.3556) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0368 (0.0734) contrast_loss 2.1035 (2.0670) lr 1.9921e-03 eta 0:24:50
epoch [7/100] batch [100/160] time 0.097 (0.099) data 0.000 (0.002) loss 4.4803 (4.5245) cls_loss 1.0708 (1.2494) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0902 (0.0690) contrast_loss 2.0113 (2.0463) lr 1.9877e-03 eta 0:24:36
epoch [8/100] batch [100/160] time 0.097 (0.099) data 0.000 (0.002) loss 10.2407 (5.0926) cls_loss 6.3038 (1.7481) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.1152 (0.0736) contrast_loss 2.3385 (2.0786) lr 1.9823e-03 eta 0:24:18
epoch [9/100] batch [100/160] time 0.097 (0.099) data 0.000 (0.002) loss 4.5030 (4.5292) cls_loss 1.1219 (1.2645) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0778 (0.0641) contrast_loss 2.0813 (2.0746) lr 1.9759e-03 eta 0:24:01
epoch [10/100] batch [100/160] time 0.099 (0.099) data 0.000 (0.002) loss 4.1431 (4.4229) cls_loss 1.0201 (1.2171) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0437 (0.0590) contrast_loss 2.0964 (2.0566) lr 1.9686e-03 eta 0:23:47
epoch [11/100] batch [100/160] time 0.096 (0.099) data 0.000 (0.002) loss 6.3281 (4.1333) cls_loss 2.4609 (0.9734) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.1410 (0.0585) contrast_loss 2.0626 (2.0148) lr 1.9603e-03 eta 0:23:28
epoch [12/100] batch [100/160] time 0.097 (0.099) data 0.000 (0.002) loss 4.1942 (4.3544) cls_loss 1.1104 (1.1564) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0542 (0.0609) contrast_loss 1.9732 (2.0338) lr 1.9511e-03 eta 0:23:12
epoch [13/100] batch [100/160] time 0.097 (0.099) data 0.000 (0.002) loss 3.8653 (4.0206) cls_loss 0.7324 (0.8683) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0455 (0.0580) contrast_loss 2.0919 (2.0113) lr 1.9409e-03 eta 0:23:04
epoch [14/100] batch [100/160] time 0.097 (0.099) data 0.000 (0.002) loss 3.6767 (4.1904) cls_loss 0.5690 (1.0512) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0449 (0.0561) contrast_loss 2.0718 (2.0133) lr 1.9298e-03 eta 0:22:43
epoch [15/100] batch [100/160] time 0.094 (0.099) data 0.000 (0.002) loss 3.7978 (3.7961) cls_loss 0.6599 (0.7156) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0497 (0.0502) contrast_loss 2.0636 (2.0020) lr 1.9178e-03 eta 0:22:28
epoch [16/100] batch [100/160] time 0.096 (0.099) data 0.000 (0.002) loss 2.9864 (3.7324) cls_loss 0.0311 (0.6683) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0410 (0.0505) contrast_loss 1.9502 (1.9829) lr 1.9048e-03 eta 0:22:13
epoch [17/100] batch [100/160] time 0.097 (0.099) data 0.000 (0.002) loss 4.3908 (3.7369) cls_loss 1.4238 (0.6938) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0243 (0.0477) contrast_loss 2.0956 (1.9844) lr 1.8910e-03 eta 0:21:56
epoch [18/100] batch [100/160] time 0.096 (0.099) data 0.000 (0.002) loss 3.1364 (3.5311) cls_loss 0.1816 (0.5519) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0374 (0.0409) contrast_loss 1.9790 (1.9748) lr 1.8763e-03 eta 0:21:41
epoch [19/100] batch [100/160] time 0.097 (0.098) data 0.000 (0.002) loss 3.2679 (3.5262) cls_loss 0.3111 (0.5583) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0427 (0.0410) contrast_loss 1.9378 (1.9627) lr 1.8607e-03 eta 0:21:22
epoch [20/100] batch [100/160] time 0.099 (0.099) data 0.000 (0.002) loss 2.8153 (3.7728) cls_loss 0.0439 (0.7444) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0254 (0.0458) contrast_loss 1.8910 (1.9848) lr 1.8443e-03 eta 0:21:16
epoch [21/100] batch [100/160] time 0.097 (0.098) data 0.000 (0.002) loss 3.0470 (3.4510) cls_loss 0.1127 (0.4729) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0394 (0.0406) contrast_loss 1.9423 (1.9763) lr 1.8271e-03 eta 0:20:50
epoch [22/100] batch [100/160] time 0.097 (0.098) data 0.000 (0.002) loss 3.2447 (3.4721) cls_loss 0.2113 (0.5244) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0419 (0.0394) contrast_loss 2.0212 (1.9555) lr 1.8090e-03 eta 0:20:34
epoch [23/100] batch [100/160] time 0.097 (0.099) data 0.000 (0.002) loss 2.8595 (3.3165) cls_loss 0.0379 (0.3979) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0281 (0.0362) contrast_loss 1.9200 (1.9522) lr 1.7902e-03 eta 0:20:22
epoch [24/100] batch [100/160] time 0.099 (0.099) data 0.000 (0.002) loss 3.1195 (3.4758) cls_loss 0.1218 (0.5373) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0399 (0.0383) contrast_loss 2.0018 (1.9554) lr 1.7705e-03 eta 0:20:08
epoch [25/100] batch [100/160] time 0.100 (0.099) data 0.000 (0.002) loss 4.9019 (3.7996) cls_loss 1.6913 (0.8022) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0614 (0.0425) contrast_loss 2.0428 (1.9803) lr 1.7501e-03 eta 0:19:54
epoch [26/100] batch [100/160] time 0.099 (0.099) data 0.000 (0.003) loss 3.1019 (3.1577) cls_loss 0.2284 (0.2859) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0312 (0.0325) contrast_loss 1.9469 (1.9349) lr 1.7290e-03 eta 0:19:38
epoch [27/100] batch [100/160] time 0.099 (0.100) data 0.000 (0.003) loss 4.2615 (3.2009) cls_loss 0.9037 (0.3343) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0852 (0.0319) contrast_loss 1.9995 (1.9345) lr 1.7071e-03 eta 0:19:35
epoch [28/100] batch [100/160] time 0.098 (0.099) data 0.000 (0.002) loss 3.1603 (3.4258) cls_loss 0.2430 (0.5211) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0301 (0.0346) contrast_loss 1.9996 (1.9514) lr 1.6845e-03 eta 0:19:03
epoch [29/100] batch [100/160] time 0.076 (0.098) data 0.000 (0.002) loss 2.9079 (3.4850) cls_loss 0.1177 (0.5742) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0252 (0.0354) contrast_loss 1.9119 (1.9507) lr 1.6613e-03 eta 0:18:42
epoch [30/100] batch [100/160] time 0.098 (0.099) data 0.000 (0.002) loss 3.1620 (3.3795) cls_loss 0.3245 (0.4942) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0184 (0.0323) contrast_loss 2.0133 (1.9503) lr 1.6374e-03 eta 0:18:29
epoch [31/100] batch [100/160] time 0.096 (0.099) data 0.000 (0.002) loss 2.8832 (3.1397) cls_loss 0.0515 (0.3114) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0251 (0.0275) contrast_loss 1.9536 (1.9313) lr 1.6129e-03 eta 0:18:15
epoch [32/100] batch [100/160] time 0.097 (0.099) data 0.000 (0.002) loss 2.8547 (2.9822) cls_loss 0.1264 (0.1904) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0213 (0.0247) contrast_loss 1.8812 (1.9169) lr 1.5878e-03 eta 0:17:59
epoch [33/100] batch [100/160] time 0.099 (0.099) data 0.000 (0.002) loss 2.7722 (3.0147) cls_loss 0.0293 (0.2462) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0237 (0.0228) contrast_loss 1.8764 (1.9092) lr 1.5621e-03 eta 0:17:42
epoch [34/100] batch [100/160] time 0.100 (0.100) data 0.000 (0.002) loss 8.2430 (3.2211) cls_loss 4.3784 (0.4001) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.1185 (0.0271) contrast_loss 2.2394 (1.9277) lr 1.5358e-03 eta 0:17:41
epoch [35/100] batch [100/160] time 0.099 (0.099) data 0.000 (0.002) loss 2.6826 (3.3352) cls_loss 0.0476 (0.4786) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0110 (0.0305) contrast_loss 1.8703 (1.9359) lr 1.5090e-03 eta 0:17:14
epoch [36/100] batch [100/160] time 0.099 (0.099) data 0.000 (0.002) loss 2.9401 (3.0430) cls_loss 0.0418 (0.2722) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0251 (0.0231) contrast_loss 2.0208 (1.9088) lr 1.4818e-03 eta 0:16:56
epoch [37/100] batch [100/160] time 0.097 (0.099) data 0.000 (0.002) loss 2.7342 (3.3124) cls_loss 0.0903 (0.4853) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0122 (0.0283) contrast_loss 1.8696 (1.9240) lr 1.4540e-03 eta 0:16:40
epoch [38/100] batch [100/160] time 0.097 (0.099) data 0.000 (0.003) loss 2.9557 (3.0667) cls_loss 0.0986 (0.2815) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0253 (0.0240) contrast_loss 1.9778 (1.9164) lr 1.4258e-03 eta 0:16:28
epoch [39/100] batch [100/160] time 0.097 (0.099) data 0.000 (0.002) loss 2.8640 (3.1705) cls_loss 0.0457 (0.3822) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0182 (0.0245) contrast_loss 1.9960 (1.9155) lr 1.3971e-03 eta 0:16:10
epoch [40/100] batch [100/160] time 0.097 (0.099) data 0.000 (0.002) loss 2.6863 (3.0894) cls_loss 0.0183 (0.2962) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0175 (0.0242) contrast_loss 1.8513 (1.9224) lr 1.3681e-03 eta 0:15:53
epoch [41/100] batch [100/160] time 0.097 (0.099) data 0.000 (0.002) loss 5.1100 (3.0908) cls_loss 1.8134 (0.3371) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0822 (0.0222) contrast_loss 1.9624 (1.8988) lr 1.3387e-03 eta 0:15:44
epoch [42/100] batch [100/160] time 0.096 (0.099) data 0.000 (0.002) loss 2.8384 (3.0501) cls_loss 0.0632 (0.3188) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0192 (0.0193) contrast_loss 1.9445 (1.8999) lr 1.3090e-03 eta 0:15:21
epoch [43/100] batch [100/160] time 0.050 (0.090) data 0.000 (0.002) loss 2.9451 (2.8927) cls_loss 0.0624 (0.1805) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0242 (0.0183) contrast_loss 2.0117 (1.8892) lr 1.2790e-03 eta 0:13:45
epoch [44/100] batch [100/160] time 0.096 (0.098) data 0.000 (0.002) loss 2.5884 (3.2884) cls_loss 0.0243 (0.5052) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0107 (0.0246) contrast_loss 1.8011 (1.9096) lr 1.2487e-03 eta 0:14:46
epoch [45/100] batch [100/160] time 0.094 (0.099) data 0.000 (0.002) loss 3.0263 (2.9870) cls_loss 0.1562 (0.2348) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0239 (0.0209) contrast_loss 2.0022 (1.9077) lr 1.2181e-03 eta 0:14:34
epoch [46/100] batch [100/160] time 0.100 (0.098) data 0.000 (0.002) loss 3.4070 (3.1216) cls_loss 0.3600 (0.3425) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0458 (0.0242) contrast_loss 2.0038 (1.9089) lr 1.1874e-03 eta 0:14:16
epoch [47/100] batch [100/160] time 0.097 (0.099) data 0.000 (0.002) loss 2.5564 (2.9576) cls_loss 0.0398 (0.2526) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0089 (0.0174) contrast_loss 1.7683 (1.8887) lr 1.1564e-03 eta 0:14:01
epoch [48/100] batch [100/160] time 0.181 (0.100) data 0.000 (0.002) loss 2.8189 (3.0318) cls_loss 0.0488 (0.2949) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0173 (0.0200) contrast_loss 1.9552 (1.9001) lr 1.1253e-03 eta 0:13:56
epoch [49/100] batch [100/160] time 0.096 (0.098) data 0.000 (0.002) loss 2.6950 (2.8971) cls_loss 0.0426 (0.1888) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0153 (0.0184) contrast_loss 1.8527 (1.8840) lr 1.0941e-03 eta 0:13:29
epoch [50/100] batch [100/160] time 0.094 (0.099) data 0.000 (0.002) loss 2.5911 (2.9203) cls_loss 0.0136 (0.2122) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0097 (0.0168) contrast_loss 1.8228 (1.8969) lr 1.0628e-03 eta 0:13:17
epoch [51/100] batch [100/160] time 0.097 (0.099) data 0.000 (0.002) loss 2.5889 (2.7921) cls_loss 0.0175 (0.1259) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0099 (0.0146) contrast_loss 1.8154 (1.8725) lr 1.0314e-03 eta 0:12:58
epoch [52/100] batch [100/160] time 0.094 (0.099) data 0.000 (0.002) loss 2.8146 (2.6959) cls_loss 0.0697 (0.0528) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0123 (0.0118) contrast_loss 1.9698 (1.8714) lr 1.0000e-03 eta 0:12:45
epoch [53/100] batch [100/160] time 0.094 (0.098) data 0.000 (0.002) loss 2.5645 (2.6875) cls_loss 0.0345 (0.0579) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0078 (0.0116) contrast_loss 1.7907 (1.8601) lr 9.6859e-04 eta 0:12:25
epoch [54/100] batch [100/160] time 0.096 (0.099) data 0.000 (0.002) loss 2.6437 (2.8817) cls_loss 0.0204 (0.2072) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0085 (0.0145) contrast_loss 1.8782 (1.8816) lr 9.3721e-04 eta 0:12:13
epoch [55/100] batch [100/160] time 0.096 (0.099) data 0.000 (0.002) loss 2.8161 (2.6695) cls_loss 0.1057 (0.0476) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0109 (0.0110) contrast_loss 1.9462 (1.8569) lr 9.0589e-04 eta 0:11:58
epoch [56/100] batch [100/160] time 0.097 (0.099) data 0.000 (0.002) loss 2.5933 (2.9065) cls_loss 0.0229 (0.2424) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0085 (0.0144) contrast_loss 1.8252 (1.8719) lr 8.7467e-04 eta 0:11:41
epoch [57/100] batch [100/160] time 0.094 (0.099) data 0.000 (0.002) loss 2.5483 (2.7767) cls_loss 0.0298 (0.1215) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0059 (0.0130) contrast_loss 1.7946 (1.8743) lr 8.4357e-04 eta 0:11:25
epoch [58/100] batch [100/160] time 0.050 (0.054) data 0.000 (0.003) loss 2.8609 (2.8173) cls_loss 0.0690 (0.1689) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0160 (0.0134) contrast_loss 1.9872 (1.8640) lr 8.1262e-04 eta 0:06:03
epoch [59/100] batch [100/160] time 0.102 (0.101) data 0.000 (0.003) loss 2.7799 (2.7544) cls_loss 0.0628 (0.1209) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0138 (0.0129) contrast_loss 1.9298 (1.8536) lr 7.8186e-04 eta 0:11:09
epoch [60/100] batch [100/160] time 0.100 (0.102) data 0.000 (0.003) loss 2.7215 (2.8627) cls_loss 0.0418 (0.1975) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0115 (0.0146) contrast_loss 1.9107 (1.8717) lr 7.5131e-04 eta 0:10:59
epoch [61/100] batch [100/160] time 0.100 (0.102) data 0.000 (0.002) loss 2.5507 (2.9393) cls_loss 0.0277 (0.2439) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0090 (0.0178) contrast_loss 1.7741 (1.8764) lr 7.2101e-04 eta 0:10:39
epoch [62/100] batch [100/160] time 0.101 (0.102) data 0.000 (0.003) loss 2.8470 (2.7271) cls_loss 0.0703 (0.0951) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0114 (0.0113) contrast_loss 2.0086 (1.8649) lr 6.9098e-04 eta 0:10:26
epoch [63/100] batch [100/160] time 0.099 (0.100) data 0.000 (0.002) loss 2.5825 (2.8114) cls_loss 0.0174 (0.1677) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0075 (0.0123) contrast_loss 1.8282 (1.8683) lr 6.6126e-04 eta 0:09:56
epoch [64/100] batch [100/160] time 0.101 (0.101) data 0.000 (0.002) loss 2.5800 (2.6552) cls_loss 0.0151 (0.0491) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0080 (0.0094) contrast_loss 1.8236 (1.8536) lr 6.3188e-04 eta 0:09:47
epoch [65/100] batch [100/160] time 0.099 (0.101) data 0.000 (0.002) loss 2.5396 (2.6332) cls_loss 0.0155 (0.0366) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0062 (0.0085) contrast_loss 1.7979 (1.8520) lr 6.0285e-04 eta 0:09:32
epoch [66/100] batch [100/160] time 0.099 (0.101) data 0.000 (0.003) loss 2.5311 (2.6841) cls_loss 0.0128 (0.0856) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0061 (0.0096) contrast_loss 1.7924 (1.8444) lr 5.7422e-04 eta 0:09:14
epoch [67/100] batch [100/160] time 0.099 (0.101) data 0.000 (0.003) loss 2.5420 (2.7339) cls_loss 0.0190 (0.1136) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0069 (0.0106) contrast_loss 1.7911 (1.8582) lr 5.4601e-04 eta 0:09:00
epoch [68/100] batch [100/160] time 0.099 (0.102) data 0.000 (0.002) loss 2.7670 (2.9177) cls_loss 0.0322 (0.2647) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0134 (0.0129) contrast_loss 1.9509 (1.8725) lr 5.1825e-04 eta 0:08:48
epoch [69/100] batch [100/160] time 0.099 (0.101) data 0.000 (0.002) loss 2.6045 (2.6621) cls_loss 0.0253 (0.0572) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0103 (0.0097) contrast_loss 1.8195 (1.8504) lr 4.9096e-04 eta 0:08:27
epoch [70/100] batch [100/160] time 0.099 (0.102) data 0.000 (0.002) loss 2.5428 (2.7152) cls_loss 0.0112 (0.0884) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0068 (0.0110) contrast_loss 1.7999 (1.8615) lr 4.6417e-04 eta 0:08:15
epoch [71/100] batch [100/160] time 0.099 (0.101) data 0.000 (0.002) loss 2.6101 (2.8158) cls_loss 0.0126 (0.1742) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0074 (0.0122) contrast_loss 1.8612 (1.8670) lr 4.3792e-04 eta 0:07:54
epoch [72/100] batch [100/160] time 0.099 (0.098) data 0.000 (0.002) loss 2.6012 (2.7424) cls_loss 0.0116 (0.1131) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0074 (0.0118) contrast_loss 1.8534 (1.8581) lr 4.1221e-04 eta 0:07:25
epoch [73/100] batch [100/160] time 0.098 (0.101) data 0.000 (0.002) loss 2.5096 (2.6874) cls_loss 0.0136 (0.0759) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0066 (0.0102) contrast_loss 1.7660 (1.8528) lr 3.8709e-04 eta 0:07:21
epoch [74/100] batch [100/160] time 0.099 (0.102) data 0.000 (0.002) loss 2.5535 (2.7778) cls_loss 0.0300 (0.1536) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0064 (0.0114) contrast_loss 1.7955 (1.8559) lr 3.6258e-04 eta 0:07:09
epoch [75/100] batch [100/160] time 0.099 (0.101) data 0.000 (0.002) loss 2.7628 (2.7546) cls_loss 0.0420 (0.1392) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0105 (0.0104) contrast_loss 1.9596 (1.8557) lr 3.3869e-04 eta 0:06:50
epoch [76/100] batch [100/160] time 0.099 (0.102) data 0.000 (0.002) loss 2.5439 (2.6661) cls_loss 0.0262 (0.0650) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0048 (0.0093) contrast_loss 1.8020 (1.8498) lr 3.1545e-04 eta 0:06:37
epoch [77/100] batch [100/160] time 0.100 (0.102) data 0.000 (0.002) loss 2.5181 (2.6910) cls_loss 0.0331 (0.0860) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0061 (0.0102) contrast_loss 1.7595 (1.8464) lr 2.9289e-04 eta 0:06:22
epoch [78/100] batch [100/160] time 0.099 (0.101) data 0.000 (0.002) loss 2.5612 (2.6099) cls_loss 0.0165 (0.0286) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0074 (0.0076) contrast_loss 1.8086 (1.8433) lr 2.7103e-04 eta 0:06:01
epoch [79/100] batch [100/160] time 0.099 (0.102) data 0.000 (0.003) loss 2.6910 (2.6015) cls_loss 0.0267 (0.0250) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0096 (0.0075) contrast_loss 1.9108 (1.8392) lr 2.4989e-04 eta 0:05:49
epoch [80/100] batch [100/160] time 0.100 (0.102) data 0.000 (0.002) loss 7.5636 (2.7302) cls_loss 4.0647 (0.1188) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0916 (0.0104) contrast_loss 2.0891 (1.8513) lr 2.2949e-04 eta 0:05:31
epoch [81/100] batch [100/160] time 0.099 (0.099) data 0.000 (0.002) loss 2.5278 (2.6088) cls_loss 0.0183 (0.0313) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0057 (0.0078) contrast_loss 1.7871 (1.8384) lr 2.0984e-04 eta 0:05:07
epoch [82/100] batch [100/160] time 0.099 (0.102) data 0.000 (0.002) loss 2.5202 (2.6902) cls_loss 0.0208 (0.0969) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0062 (0.0094) contrast_loss 1.7732 (1.8407) lr 1.9098e-04 eta 0:04:59
epoch [83/100] batch [100/160] time 0.099 (0.101) data 0.000 (0.002) loss 2.9366 (2.6607) cls_loss 0.1454 (0.0682) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0222 (0.0086) contrast_loss 1.9366 (1.8465) lr 1.7292e-04 eta 0:04:42
epoch [84/100] batch [100/160] time 0.099 (0.103) data 0.000 (0.003) loss 2.5352 (2.6371) cls_loss 0.0188 (0.0501) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0055 (0.0078) contrast_loss 1.7952 (1.8473) lr 1.5567e-04 eta 0:04:28
epoch [85/100] batch [100/160] time 0.100 (0.102) data 0.000 (0.002) loss 2.6035 (2.6826) cls_loss 0.0177 (0.0723) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0060 (0.0098) contrast_loss 1.8606 (1.8547) lr 1.3926e-04 eta 0:04:10
epoch [86/100] batch [100/160] time 0.099 (0.099) data 0.000 (0.002) loss 2.5390 (2.5978) cls_loss 0.0185 (0.0258) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0066 (0.0074) contrast_loss 1.7908 (1.8356) lr 1.2369e-04 eta 0:03:46
epoch [87/100] batch [100/160] time 0.100 (0.102) data 0.000 (0.002) loss 2.5928 (2.6297) cls_loss 0.0152 (0.0383) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0061 (0.0082) contrast_loss 1.8523 (1.8487) lr 1.0899e-04 eta 0:03:38
epoch [88/100] batch [100/160] time 0.099 (0.101) data 0.000 (0.002) loss 6.5651 (2.6978) cls_loss 2.9759 (0.0992) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.1045 (0.0096) contrast_loss 2.0765 (1.8446) lr 9.5173e-05 eta 0:03:19
epoch [89/100] batch [100/160] time 0.097 (0.101) data 0.000 (0.002) loss 2.6995 (2.6460) cls_loss 0.0325 (0.0659) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0097 (0.0083) contrast_loss 1.9128 (1.8369) lr 8.2245e-05 eta 0:03:03
epoch [90/100] batch [100/160] time 0.098 (0.101) data 0.000 (0.003) loss 2.6741 (2.7125) cls_loss 0.0241 (0.1116) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0094 (0.0098) contrast_loss 1.8975 (1.8458) lr 7.0224e-05 eta 0:02:48
epoch [91/100] batch [100/160] time 0.100 (0.104) data 0.000 (0.003) loss 2.7166 (2.6578) cls_loss 0.0349 (0.0616) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0096 (0.0090) contrast_loss 1.9283 (1.8476) lr 5.9119e-05 eta 0:02:35
epoch [92/100] batch [100/160] time 0.101 (0.102) data 0.000 (0.003) loss 2.6744 (2.7066) cls_loss 0.0218 (0.1050) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0097 (0.0096) contrast_loss 1.8978 (1.8476) lr 4.8943e-05 eta 0:02:17
epoch [93/100] batch [100/160] time 0.099 (0.101) data 0.000 (0.002) loss 2.5918 (2.6509) cls_loss 0.0169 (0.0621) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0057 (0.0081) contrast_loss 1.8520 (1.8469) lr 3.9706e-05 eta 0:01:59
epoch [94/100] batch [100/160] time 0.100 (0.102) data 0.000 (0.003) loss 2.7564 (2.6478) cls_loss 0.0512 (0.0601) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0101 (0.0079) contrast_loss 1.9473 (1.8478) lr 3.1417e-05 eta 0:01:44
epoch [95/100] batch [100/160] time 0.099 (0.098) data 0.000 (0.002) loss 2.7361 (2.6092) cls_loss 0.0407 (0.0287) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0101 (0.0074) contrast_loss 1.9376 (1.8447) lr 2.4083e-05 eta 0:01:24
epoch [96/100] batch [100/160] time 0.100 (0.102) data 0.000 (0.002) loss 2.5452 (2.6136) cls_loss 0.0127 (0.0291) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0061 (0.0074) contrast_loss 1.8063 (1.8480) lr 1.7713e-05 eta 0:01:11
epoch [97/100] batch [100/160] time 0.099 (0.102) data 0.000 (0.002) loss 2.7486 (2.6978) cls_loss 0.0432 (0.1105) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0097 (0.0086) contrast_loss 1.9506 (1.8414) lr 1.2312e-05 eta 0:00:54
epoch [98/100] batch [100/160] time 0.099 (0.101) data 0.000 (0.002) loss 2.5013 (2.6295) cls_loss 0.0139 (0.0411) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0057 (0.0083) contrast_loss 1.7645 (1.8451) lr 7.8853e-06 eta 0:00:38
epoch [99/100] batch [100/160] time 0.099 (0.101) data 0.000 (0.003) loss 2.5066 (2.6047) cls_loss 0.0201 (0.0298) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0051 (0.0073) contrast_loss 1.7686 (1.8395) lr 4.4380e-06 eta 0:00:22
epoch [100/100] batch [100/160] time 0.099 (0.102) data 0.000 (0.003) loss 2.7522 (2.6229) cls_loss 0.0462 (0.0378) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0096 (0.0082) contrast_loss 1.9521 (1.8429) lr 1.9733e-06 eta 0:00:06
Checkpoint saved to /CEPL_outputs/few_shots/CEPL_L_16shot/eurosat/vit_b16_cepl_16shots/seed2/efficient_prompt/model.pth.tar-100
Finish training
Deploy the last-epoch model
Evaluate on the *test* set
=> result
* total: 8,100
* correct: 7,662
* accuracy: 94.593%
* error: 5.4%
* macro_f1: 94.491%
Elapsed: 1:06:05
