***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/EFF_Prompts/vit_b16_cepl.yaml
dataset_config_file: configs/datasets/oxford_pets.yaml
eval_only: False
head: 
load_epoch: None
model_dir: 
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'TRAINER.EFF_PROMPTS.N_CTX', '32', 'TRAINER.EFF_PROMPTS.CL', 'EFF_Prompts', 'TRAINER.EFF_PROMPTS.PREC', 'fp32', 'OPTIM.MAX_EPOCH', '20']
output_dir: /oxford_pets/vit_b16_cepl_16shots/seed2
resume: 
root: 
seed: 2
source_domains: None
target_domains: None
trainer: EFF_Prompts_4
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 1
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 1
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: OxfordPets
  NUM_LABELED: -1
  NUM_SHOTS: 16
  ROOT: 
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 20
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: /oxford_pets/vit_b16_cepl_16shots/seed2
RESUME: 
SEED: 2
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 100
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  CEPL:
    ALPHA: 1.0
    CL: EFF_Prompts
    CTX_INIT: 
    N_CTX: 32
    PREC: fp32
    w1: 1.0
    w2: 8.0
  COCOOP:
    CTX_INIT: a photo of a
    N_CTX: 4
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  EFF_PROMPTS:
    ALPHA: 1.0
    CL: EFF_Prompts
    CTX_INIT: 
    N_CTX: 32
    PREC: fp32
    w1: 1.0
    w2: 8.0
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: EFF_Prompts_4
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Loading trainer: EFF_Prompts_4
Loading dataset: OxfordPets
Reading split from /oxford_pets/split_zhou_OxfordPets.json
Loading preprocessed few-shot data from /oxford_pets/split_fewshot/shot_16-seed_2.pkl
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ----------
Dataset    OxfordPets
# classes  37
# train_x  592
# val      148
# test     3,669
---------  ----------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X."
Number of context words (tokens): 32
Building text dataset per class...


Using linear_head: no norm scale, with bias. And lr should be 0.002 -> 1e-5 !
Turning off gradients in both the image and the text encoder
Parameters to be updated: {'image_encoder.transformer.resblocks.4.mlp.c_fc.linear.lora_A', 'text_encoder.transformer.resblocks.3.attn.lora_out_proj_A', 'image_encoder.transformer.resblocks.4.attn.lora_V_B', 'image_encoder.transformer.resblocks.10.mlp.c_fc.linear.lora_B', 'image_encoder.transformer.resblocks.10.attn.lora_K_B', 'text_encoder.transformer.resblocks.5.attn.lora_Q_A', 'text_encoder.transformer.resblocks.6.attn.lora_V_A', 'text_encoder.transformer.resblocks.8.attn.lora_out_proj_A', 'image_encoder.transformer.resblocks.4.mlp.c_proj.linear.lora_A', 'image_encoder.transformer.resblocks.6.attn.lora_Q_A', 'text_encoder.transformer.resblocks.7.attn.lora_out_proj_B', 'image_encoder.transformer.resblocks.11.attn.lora_K_B', 'text_encoder.transformer.resblocks.11.attn.lora_K_A', 'text_encoder.transformer.resblocks.4.attn.lora_out_proj_A', 'text_encoder.transformer.resblocks.6.mlp.c_fc.linear.lora_A', 'text_encoder.transformer.resblocks.8.mlp.c_fc.linear.lora_A', 'text_encoder.transformer.resblocks.3.attn.lora_K_A', 'image_encoder.transformer.resblocks.6.mlp.c_proj.linear.lora_A', 'text_encoder.transformer.resblocks.6.attn.lora_Q_A', 'text_encoder.transformer.resblocks.8.mlp.c_fc.linear.lora_B', 'text_encoder.transformer.resblocks.11.attn.lora_K_B', 'trans_block.atten.ln_2.weight', 'text_encoder.transformer.resblocks.6.mlp.c_proj.linear.lora_A', 'image_encoder.transformer.resblocks.6.attn.lora_V_B', 'image_encoder.transformer.resblocks.9.attn.lora_K_B', 'image_encoder.transformer.resblocks.5.attn.lora_V_B', 'text_encoder.transformer.resblocks.8.mlp.c_proj.linear.lora_A', 'image_encoder.transformer.resblocks.10.mlp.c_proj.linear.lora_A', 'image_encoder.transformer.resblocks.7.attn.lora_K_B', 'text_encoder.transformer.resblocks.5.mlp.c_fc.linear.lora_A', 'text_encoder.transformer.resblocks.8.mlp.c_proj.linear.lora_B', 'trans_block.atten.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.9.attn.lora_Q_B', 'prompt_learner.meta_net.linear2.weight', 'image_encoder.transformer.resblocks.10.mlp.c_proj.linear.lora_B', 'image_encoder.transformer.resblocks.6.attn.lora_out_proj_A', 'text_encoder.transformer.resblocks.3.attn.lora_V_A', 'text_encoder.transformer.resblocks.3.mlp.c_fc.linear.lora_A', 'text_encoder.transformer.resblocks.7.mlp.c_proj.linear.lora_B', 'text_encoder.transformer.resblocks.9.mlp.c_fc.linear.lora_B', 'text_encoder.transformer.resblocks.6.mlp.c_proj.linear.lora_B', 'text_encoder.transformer.resblocks.9.attn.lora_V_B', 'image_encoder.transformer.resblocks.7.attn.lora_Q_B', 'text_encoder.transformer.resblocks.9.attn.lora_out_proj_B', 'image_encoder.transformer.resblocks.3.mlp.c_proj.linear.lora_B', 'image_encoder.transformer.resblocks.5.mlp.c_proj.linear.lora_A', 'image_encoder.transformer.resblocks.11.attn.lora_K_A', 'text_encoder.transformer.resblocks.4.mlp.c_fc.linear.lora_A', 'text_encoder.transformer.resblocks.11.mlp.c_proj.linear.lora_B', 'text_encoder.transformer.resblocks.3.mlp.c_proj.linear.lora_B', 'image_encoder.transformer.resblocks.11.attn.lora_Q_A', 'image_encoder.transformer.resblocks.3.attn.lora_K_A', 'image_encoder.transformer.resblocks.5.mlp.c_fc.linear.lora_B', 'text_encoder.transformer.resblocks.11.mlp.c_fc.linear.lora_A', 'embedding_weight_t', 'text_encoder.transformer.resblocks.3.attn.lora_out_proj_B', 'image_encoder.transformer.resblocks.9.mlp.c_proj.linear.lora_A', 'image_encoder.transformer.resblocks.10.attn.lora_out_proj_A', 'text_encoder.transformer.resblocks.3.mlp.c_proj.linear.lora_A', 'image_encoder.transformer.resblocks.8.mlp.c_fc.linear.lora_B', 'text_encoder.transformer.resblocks.10.attn.lora_V_B', 'text_encoder.transformer.resblocks.10.attn.lora_Q_A', 'image_encoder.transformer.resblocks.10.attn.lora_Q_B', 'text_encoder.transformer.resblocks.5.attn.lora_out_proj_A', 'text_encoder.transformer.resblocks.7.attn.lora_out_proj_A', 'text_encoder.transformer.resblocks.8.attn.lora_K_B', 'image_encoder.transformer.resblocks.7.attn.lora_Q_A', 'trans_block.atten.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.11.attn.lora_V_A', 'image_encoder.transformer.resblocks.5.mlp.c_fc.linear.lora_A', 'image_encoder.transformer.resblocks.10.mlp.c_fc.linear.lora_A', 'image_encoder.transformer.resblocks.5.attn.lora_K_A', 'image_encoder.transformer.resblocks.4.attn.lora_V_A', 'image_encoder.transformer.resblocks.8.attn.lora_V_A', 'image_encoder.transformer.resblocks.6.attn.lora_K_A', 'image_encoder.transformer.resblocks.4.attn.lora_K_B', 'image_encoder.transformer.resblocks.6.mlp.c_fc.linear.lora_B', 'text_encoder.transformer.resblocks.5.mlp.c_fc.linear.lora_B', 'text_encoder.transformer.resblocks.6.attn.lora_out_proj_B', 'text_encoder.transformer.resblocks.6.attn.lora_Q_B', 'text_encoder.transformer.resblocks.7.mlp.c_fc.linear.lora_B', 'text_encoder.transformer.resblocks.8.attn.lora_V_A', 'cls_head.bias', 'text_encoder.transformer.resblocks.7.attn.lora_K_B', 'image_encoder.transformer.resblocks.5.attn.lora_K_B', 'text_encoder.transformer.resblocks.4.mlp.c_proj.linear.lora_A', 'text_encoder.transformer.resblocks.9.attn.lora_V_A', 'image_encoder.transformer.resblocks.7.mlp.c_fc.linear.lora_A', 'image_encoder.transformer.resblocks.4.mlp.c_proj.linear.lora_B', 'image_encoder.transformer.resblocks.9.attn.lora_out_proj_B', 'image_encoder.transformer.resblocks.4.attn.lora_Q_B', 'image_encoder.transformer.resblocks.7.attn.lora_K_A', 'image_encoder.transformer.resblocks.4.attn.lora_Q_A', 'image_encoder.transformer.resblocks.10.attn.lora_K_A', 'text_encoder.transformer.resblocks.3.mlp.c_fc.linear.lora_B', 'image_encoder.transformer.resblocks.3.attn.lora_Q_B', 'text_encoder.transformer.resblocks.6.attn.lora_K_A', 'text_encoder.transformer.resblocks.9.mlp.c_proj.linear.lora_B', 'image_encoder.transformer.resblocks.8.attn.lora_V_B', 'text_encoder.transformer.resblocks.7.mlp.c_proj.linear.lora_A', 'image_encoder.transformer.resblocks.8.attn.lora_Q_B', 'image_encoder.transformer.resblocks.7.attn.lora_out_proj_A', 'trans_block.atten.ln_1.weight', 'image_encoder.transformer.resblocks.11.attn.lora_V_A', 'image_encoder.transformer.resblocks.7.attn.lora_V_A', 'text_encoder.transformer.resblocks.3.attn.lora_V_B', 'image_encoder.transformer.resblocks.11.attn.lora_out_proj_B', 'trans_block.ln_post.weight', 'text_encoder.transformer.resblocks.4.attn.lora_out_proj_B', 'image_encoder.transformer.resblocks.3.attn.lora_V_B', 'trans_block.atten.attn.in_proj_weight', 'image_encoder.transformer.resblocks.6.attn.lora_out_proj_B', 'prompt_learner.meta_net.linear1.weight', 'text_encoder.transformer.resblocks.3.attn.lora_Q_A', 'image_encoder.transformer.resblocks.7.mlp.c_proj.linear.lora_A', 'image_encoder.transformer.resblocks.5.attn.lora_V_A', 'text_encoder.transformer.resblocks.11.attn.lora_out_proj_B', 'prompt_learner.meta_net.linear2.bias', 'image_encoder.transformer.resblocks.9.attn.lora_V_A', 'image_encoder.transformer.resblocks.10.attn.lora_V_B', 'image_encoder.transformer.resblocks.5.attn.lora_out_proj_B', 'text_encoder.transformer.resblocks.10.attn.lora_V_A', 'text_encoder.transformer.resblocks.7.attn.lora_V_B', 'text_encoder.transformer.resblocks.7.attn.lora_Q_A', 'image_encoder.transformer.resblocks.7.mlp.c_proj.linear.lora_B', 'image_encoder.transformer.resblocks.4.attn.lora_K_A', 'image_encoder.transformer.resblocks.8.attn.lora_out_proj_B', 'image_encoder.transformer.resblocks.9.mlp.c_proj.linear.lora_B', 'text_encoder.transformer.resblocks.4.attn.lora_Q_B', 'image_encoder.transformer.resblocks.8.attn.lora_out_proj_A', 'image_encoder.transformer.resblocks.5.mlp.c_proj.linear.lora_B', 'image_encoder.transformer.resblocks.8.attn.lora_K_B', 'text_encoder.transformer.resblocks.9.attn.lora_K_B', 'text_encoder.transformer.resblocks.10.attn.lora_K_B', 'image_encoder.transformer.resblocks.11.mlp.c_fc.linear.lora_A', 'image_encoder.transformer.resblocks.3.mlp.c_proj.linear.lora_A', 'image_encoder.transformer.resblocks.3.attn.lora_out_proj_B', 'image_encoder.transformer.resblocks.3.attn.lora_Q_A', 'text_encoder.transformer.resblocks.9.attn.lora_Q_A', 'image_encoder.transformer.resblocks.8.mlp.c_proj.linear.lora_B', 'text_encoder.transformer.resblocks.9.mlp.c_proj.linear.lora_A', 'image_encoder.transformer.resblocks.4.attn.lora_out_proj_A', 'text_encoder.transformer.resblocks.8.attn.lora_V_B', 'text_encoder.transformer.resblocks.5.attn.lora_out_proj_B', 'trans_block.atten.attn.in_proj_bias', 'image_encoder.transformer.resblocks.6.attn.lora_V_A', 'text_encoder.transformer.resblocks.5.attn.lora_K_B', 'image_encoder.transformer.resblocks.9.attn.lora_V_B', 'image_encoder.transformer.resblocks.9.attn.lora_Q_A', 'image_encoder.transformer.resblocks.11.attn.lora_Q_B', 'image_encoder.transformer.resblocks.11.mlp.c_proj.linear.lora_B', 'text_encoder.transformer.resblocks.4.mlp.c_proj.linear.lora_B', 'text_encoder.transformer.resblocks.5.attn.lora_K_A', 'image_encoder.transformer.resblocks.6.mlp.c_fc.linear.lora_A', 'prompt_learner.meta_net.linear1.bias', 'image_encoder.transformer.resblocks.9.mlp.c_fc.linear.lora_B', 'text_encoder.transformer.resblocks.7.attn.lora_Q_B', 'text_encoder.transformer.resblocks.9.attn.lora_out_proj_A', 'text_encoder.transformer.resblocks.4.attn.lora_V_A', 'text_encoder.transformer.resblocks.11.attn.lora_V_B', 'text_encoder.transformer.resblocks.10.attn.lora_out_proj_A', 'text_encoder.transformer.resblocks.5.mlp.c_proj.linear.lora_B', 'image_encoder.transformer.resblocks.3.attn.lora_K_B', 'image_encoder.transformer.resblocks.7.mlp.c_fc.linear.lora_B', 'text_encoder.transformer.resblocks.4.attn.lora_Q_A', 'text_encoder.transformer.resblocks.4.attn.lora_K_A', 'trans_block.atten.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.5.mlp.c_proj.linear.lora_A', 'trans_block.proj', 'image_encoder.transformer.resblocks.11.mlp.c_proj.linear.lora_A', 'text_encoder.transformer.resblocks.8.attn.lora_Q_A', 'image_encoder.transformer.resblocks.7.attn.lora_V_B', 'text_encoder.transformer.resblocks.10.mlp.c_fc.linear.lora_A', 'text_encoder.transformer.resblocks.4.attn.lora_V_B', 'image_encoder.transformer.resblocks.5.attn.lora_Q_A', 'text_encoder.transformer.resblocks.9.attn.lora_Q_B', 'image_encoder.transformer.resblocks.3.attn.lora_out_proj_A', 'text_encoder.transformer.resblocks.11.mlp.c_proj.linear.lora_A', 'image_encoder.transformer.resblocks.8.attn.lora_Q_A', 'image_encoder.transformer.resblocks.3.attn.lora_V_A', 'trans_block.atten.attn.out_proj.bias', 'text_encoder.transformer.resblocks.9.mlp.c_fc.linear.lora_A', 'text_encoder.transformer.resblocks.6.attn.lora_out_proj_A', 'trans_block.atten.attn.out_proj.weight', 'text_encoder.transformer.resblocks.8.attn.lora_Q_B', 'image_encoder.transformer.resblocks.10.attn.lora_Q_A', 'text_encoder.transformer.resblocks.10.mlp.c_fc.linear.lora_B', 'image_encoder.transformer.resblocks.10.attn.lora_out_proj_B', 'text_encoder.transformer.resblocks.5.attn.lora_V_A', 'text_encoder.transformer.resblocks.6.attn.lora_K_B', 'image_encoder.transformer.resblocks.9.attn.lora_out_proj_A', 'trans_block.ln_post.bias', 'image_encoder.transformer.resblocks.3.mlp.c_fc.linear.lora_A', 'text_encoder.transformer.resblocks.9.attn.lora_K_A', 'text_encoder.transformer.resblocks.10.mlp.c_proj.linear.lora_B', 'image_encoder.transformer.resblocks.4.mlp.c_fc.linear.lora_B', 'prompt_learner.ctx', 'text_encoder.transformer.resblocks.8.attn.lora_K_A', 'text_encoder.transformer.resblocks.11.attn.lora_out_proj_A', 'image_encoder.transformer.resblocks.11.attn.lora_V_B', 'image_encoder.transformer.resblocks.6.mlp.c_proj.linear.lora_B', 'image_encoder.transformer.resblocks.8.attn.lora_K_A', 'text_encoder.transformer.resblocks.8.attn.lora_out_proj_B', 'text_encoder.transformer.resblocks.11.attn.lora_Q_A', 'text_encoder.transformer.resblocks.7.attn.lora_V_A', 'trans_block.atten.ln_2.bias', 'text_encoder.transformer.resblocks.10.attn.lora_K_A', 'image_encoder.transformer.resblocks.5.attn.lora_Q_B', 'text_encoder.transformer.resblocks.5.attn.lora_Q_B', 'image_encoder.transformer.resblocks.8.mlp.c_fc.linear.lora_A', 'text_encoder.transformer.resblocks.10.attn.lora_Q_B', 'image_encoder.transformer.resblocks.11.mlp.c_fc.linear.lora_B', 'text_encoder.transformer.resblocks.11.mlp.c_fc.linear.lora_B', 'text_encoder.transformer.resblocks.6.attn.lora_V_B', 'image_encoder.transformer.resblocks.3.mlp.c_fc.linear.lora_B', 'image_encoder.transformer.resblocks.4.attn.lora_out_proj_B', 'trans_block.atten.ln_1.bias', 'trans_block.atten.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.6.attn.lora_K_B', 'image_encoder.transformer.resblocks.7.attn.lora_out_proj_B', 'text_encoder.transformer.resblocks.7.mlp.c_fc.linear.lora_A', 'text_encoder.transformer.resblocks.3.attn.lora_Q_B', 'image_encoder.transformer.resblocks.8.mlp.c_proj.linear.lora_A', 'text_encoder.transformer.resblocks.3.attn.lora_K_B', 'image_encoder.transformer.resblocks.10.attn.lora_V_A', 'cls_head.weight', 'text_encoder.transformer.resblocks.7.attn.lora_K_A', 'image_encoder.transformer.resblocks.9.attn.lora_K_A', 'text_encoder.transformer.resblocks.4.attn.lora_K_B', 'image_encoder.transformer.resblocks.6.attn.lora_Q_B', 'text_encoder.transformer.resblocks.11.attn.lora_Q_B', 'image_encoder.transformer.resblocks.11.attn.lora_out_proj_A', 'image_encoder.transformer.resblocks.9.mlp.c_fc.linear.lora_A', 'text_encoder.transformer.resblocks.10.mlp.c_proj.linear.lora_A', 'image_encoder.transformer.resblocks.5.attn.lora_out_proj_A', 'text_encoder.transformer.resblocks.10.attn.lora_out_proj_B', 'text_encoder.transformer.resblocks.5.attn.lora_V_B', 'text_encoder.transformer.resblocks.4.mlp.c_fc.linear.lora_B', 'text_encoder.transformer.resblocks.6.mlp.c_fc.linear.lora_B'}
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=/oxford_pets/vit_b16_cepl_16shots/seed2/tensorboard)
epoch [1/20] batch [100/592] time 0.140 (0.203) data 0.000 (0.018) loss 16.4671 (18.0162) cls_loss 5.9921 (8.7493) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.7878 (0.6316) contrast_loss 3.4958 (3.5369) lr 1.0000e-05 eta 0:39:39
epoch [1/20] batch [200/592] time 0.156 (0.174) data 0.000 (0.009) loss 16.0342 (16.3750) cls_loss 5.6049 (6.7118) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.7770 (0.6811) contrast_loss 3.5362 (3.5373) lr 1.0000e-05 eta 0:33:48
epoch [1/20] batch [300/592] time 0.142 (0.164) data 0.000 (0.006) loss 16.4718 (15.7022) cls_loss 5.9925 (5.8807) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.7818 (0.7013) contrast_loss 3.5478 (3.5345) lr 1.0000e-05 eta 0:31:34
epoch [1/20] batch [400/592] time 0.136 (0.159) data 0.000 (0.005) loss 15.8538 (15.3007) cls_loss 5.2057 (5.3906) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.8093 (0.7124) contrast_loss 3.4967 (3.5337) lr 1.0000e-05 eta 0:30:22
epoch [1/20] batch [500/592] time 0.140 (0.156) data 0.000 (0.004) loss 16.2120 (15.0483) cls_loss 5.5749 (5.1075) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.8054 (0.7163) contrast_loss 3.5172 (3.5332) lr 1.0000e-05 eta 0:29:32
epoch [2/20] batch [100/592] time 0.145 (0.150) data 0.000 (0.005) loss 15.0812 (41.7722) cls_loss 7.4973 (32.7888) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.4264 (0.5966) contrast_loss 3.4956 (3.5333) lr 2.0000e-03 eta 0:27:48
epoch [2/20] batch [200/592] time 0.146 (0.148) data 0.000 (0.002) loss 9.5147 (26.8019) cls_loss 2.2220 (18.4934) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.4075 (0.5192) contrast_loss 3.3558 (3.4777) lr 2.0000e-03 eta 0:27:15
epoch [2/20] batch [300/592] time 0.140 (0.147) data 0.000 (0.002) loss 8.6154 (21.1617) cls_loss 1.8661 (13.3147) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.3394 (0.4656) contrast_loss 3.3571 (3.4452) lr 2.0000e-03 eta 0:26:47
epoch [2/20] batch [400/592] time 0.145 (0.147) data 0.000 (0.002) loss 8.8129 (18.1656) cls_loss 2.7127 (10.6556) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.2395 (0.4257) contrast_loss 3.5077 (3.4270) lr 2.0000e-03 eta 0:26:31
epoch [2/20] batch [500/592] time 0.147 (0.146) data 0.000 (0.001) loss 17.0283 (16.3784) cls_loss 10.4698 (9.0906) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.2825 (0.3996) contrast_loss 3.6214 (3.4143) lr 2.0000e-03 eta 0:26:11
epoch [3/20] batch [100/592] time 0.145 (0.150) data 0.000 (0.005) loss 9.2711 (8.7506) cls_loss 3.1195 (2.5332) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.2746 (0.2747) contrast_loss 3.2782 (3.3431) lr 1.9877e-03 eta 0:26:23
epoch [3/20] batch [200/592] time 0.140 (0.147) data 0.000 (0.003) loss 8.9641 (8.5531) cls_loss 2.4796 (2.3890) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.3133 (0.2697) contrast_loss 3.3010 (3.3299) lr 1.9877e-03 eta 0:25:39
epoch [3/20] batch [300/592] time 0.142 (0.147) data 0.000 (0.002) loss 7.9430 (8.4414) cls_loss 2.1502 (2.3262) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.2253 (0.2646) contrast_loss 3.3137 (3.3217) lr 1.9877e-03 eta 0:25:21
epoch [3/20] batch [400/592] time 0.144 (0.146) data 0.000 (0.002) loss 7.7487 (8.3757) cls_loss 1.6406 (2.2893) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.2801 (0.2611) contrast_loss 3.1903 (3.3208) lr 1.9877e-03 eta 0:25:00
epoch [3/20] batch [500/592] time 0.142 (0.146) data 0.000 (0.001) loss 6.8157 (8.3181) cls_loss 1.1605 (2.2699) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.2130 (0.2565) contrast_loss 3.2739 (3.3190) lr 1.9877e-03 eta 0:24:43
epoch [4/20] batch [100/592] time 0.151 (0.150) data 0.000 (0.005) loss 7.7743 (7.9759) cls_loss 1.8599 (2.0924) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.2468 (0.2389) contrast_loss 3.2631 (3.2951) lr 1.9511e-03 eta 0:24:50
epoch [4/20] batch [200/592] time 0.140 (0.147) data 0.000 (0.003) loss 8.1426 (7.8961) cls_loss 1.7086 (2.0660) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.3129 (0.2328) contrast_loss 3.2537 (3.2904) lr 1.9511e-03 eta 0:24:08
epoch [4/20] batch [300/592] time 0.138 (0.146) data 0.000 (0.002) loss 8.9169 (7.9207) cls_loss 2.2002 (2.0930) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.3353 (0.2319) contrast_loss 3.3574 (3.2958) lr 1.9511e-03 eta 0:23:44
epoch [4/20] batch [400/592] time 0.149 (0.146) data 0.000 (0.002) loss 7.2759 (7.9534) cls_loss 1.7533 (2.1216) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.1809 (0.2321) contrast_loss 3.3981 (3.2978) lr 1.9511e-03 eta 0:23:29
epoch [4/20] batch [500/592] time 0.144 (0.146) data 0.000 (0.001) loss 10.3085 (7.9306) cls_loss 3.6870 (2.1039) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.3161 (0.2315) contrast_loss 3.4153 (3.2981) lr 1.9511e-03 eta 0:23:13
epoch [5/20] batch [100/592] time 0.140 (0.150) data 0.000 (0.005) loss 7.2631 (7.6811) cls_loss 1.8350 (1.9249) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.1880 (0.2255) contrast_loss 3.2475 (3.2751) lr 1.8910e-03 eta 0:23:21
epoch [5/20] batch [200/592] time 0.155 (0.148) data 0.000 (0.003) loss 8.0103 (7.7947) cls_loss 1.8716 (2.0237) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.2771 (0.2259) contrast_loss 3.2450 (3.2867) lr 1.8910e-03 eta 0:22:49
epoch [5/20] batch [300/592] time 0.152 (0.147) data 0.000 (0.002) loss 8.2351 (7.7682) cls_loss 2.4026 (2.0121) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.2440 (0.2241) contrast_loss 3.2035 (3.2866) lr 1.8910e-03 eta 0:22:29
epoch [5/20] batch [400/592] time 0.144 (0.147) data 0.000 (0.001) loss 8.7056 (7.8021) cls_loss 3.0541 (2.0306) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.2068 (0.2262) contrast_loss 3.3205 (3.2848) lr 1.8910e-03 eta 0:22:09
epoch [5/20] batch [500/592] time 0.154 (0.146) data 0.003 (0.001) loss 7.1515 (7.7847) cls_loss 1.4506 (2.0200) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.2287 (0.2255) contrast_loss 3.1939 (3.2836) lr 1.8910e-03 eta 0:21:54
epoch [6/20] batch [100/592] time 0.136 (0.149) data 0.000 (0.004) loss 14.1479 (7.7921) cls_loss 7.8691 (1.9998) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.2509 (0.2289) contrast_loss 3.5948 (3.2841) lr 1.8090e-03 eta 0:21:48
epoch [6/20] batch [200/592] time 0.142 (0.147) data 0.000 (0.002) loss 6.8131 (7.6701) cls_loss 1.3256 (1.9249) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.1983 (0.2232) contrast_loss 3.2245 (3.2825) lr 1.8090e-03 eta 0:21:17
epoch [6/20] batch [300/592] time 0.142 (0.146) data 0.000 (0.002) loss 9.2641 (7.6930) cls_loss 4.0696 (1.9440) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.1467 (0.2236) contrast_loss 3.3440 (3.2830) lr 1.8090e-03 eta 0:20:54
epoch [6/20] batch [400/592] time 0.142 (0.146) data 0.000 (0.001) loss 6.4005 (7.6625) cls_loss 1.0082 (1.9341) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.1806 (0.2206) contrast_loss 3.2701 (3.2862) lr 1.8090e-03 eta 0:20:34
epoch [6/20] batch [500/592] time 0.168 (0.146) data 0.006 (0.001) loss 7.7599 (7.6554) cls_loss 2.0559 (1.9351) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.2247 (0.2195) contrast_loss 3.2298 (3.2873) lr 1.8090e-03 eta 0:20:20
epoch [7/20] batch [100/592] time 0.142 (0.149) data 0.000 (0.005) loss 7.0867 (7.6141) cls_loss 1.5911 (1.9434) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.1856 (0.2123) contrast_loss 3.3340 (3.2956) lr 1.7071e-03 eta 0:20:19
epoch [7/20] batch [200/592] time 0.147 (0.147) data 0.000 (0.003) loss 6.1262 (7.6833) cls_loss 0.8134 (1.9951) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.1707 (0.2151) contrast_loss 3.2704 (3.2906) lr 1.7071e-03 eta 0:19:49
epoch [7/20] batch [300/592] time 0.144 (0.147) data 0.000 (0.002) loss 8.0156 (7.5680) cls_loss 2.2060 (1.8975) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.2379 (0.2141) contrast_loss 3.2291 (3.2805) lr 1.7071e-03 eta 0:19:31
epoch [7/20] batch [400/592] time 0.136 (0.146) data 0.000 (0.002) loss 9.6985 (7.5796) cls_loss 4.1385 (1.9054) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.1841 (0.2139) contrast_loss 3.4106 (3.2857) lr 1.7071e-03 eta 0:19:15
epoch [7/20] batch [500/592] time 0.153 (0.146) data 0.000 (0.001) loss 9.8515 (7.6442) cls_loss 4.3051 (1.9607) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.1596 (0.2142) contrast_loss 3.5922 (3.2931) lr 1.7071e-03 eta 0:18:58
epoch [8/20] batch [100/592] time 0.156 (0.150) data 0.000 (0.004) loss 7.6126 (7.1417) cls_loss 1.7237 (1.5360) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.2572 (0.2078) contrast_loss 3.1547 (3.2664) lr 1.5878e-03 eta 0:18:56
epoch [8/20] batch [200/592] time 0.142 (0.147) data 0.000 (0.002) loss 7.5981 (7.1338) cls_loss 1.6491 (1.5391) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.2573 (0.2061) contrast_loss 3.2140 (3.2687) lr 1.5878e-03 eta 0:18:21
epoch [8/20] batch [300/592] time 0.145 (0.147) data 0.000 (0.002) loss 7.7087 (7.0857) cls_loss 1.3187 (1.5329) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.3140 (0.2002) contrast_loss 3.2011 (3.2739) lr 1.5878e-03 eta 0:18:03
epoch [8/20] batch [400/592] time 0.147 (0.146) data 0.000 (0.001) loss 6.3348 (7.0784) cls_loss 1.2618 (1.5222) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.1409 (0.2006) contrast_loss 3.2686 (3.2742) lr 1.5878e-03 eta 0:17:45
epoch [8/20] batch [500/592] time 0.140 (0.146) data 0.000 (0.001) loss 7.2825 (7.0549) cls_loss 1.1462 (1.5188) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.2852 (0.1981) contrast_loss 3.1780 (3.2746) lr 1.5878e-03 eta 0:17:28
epoch [9/20] batch [100/592] time 0.143 (0.150) data 0.000 (0.005) loss 7.4801 (6.9700) cls_loss 1.4294 (1.4779) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.2789 (0.1928) contrast_loss 3.1427 (3.2727) lr 1.4540e-03 eta 0:17:27
epoch [9/20] batch [200/592] time 0.157 (0.148) data 0.000 (0.003) loss 6.6075 (6.9846) cls_loss 1.3862 (1.4822) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.1660 (0.1939) contrast_loss 3.2160 (3.2740) lr 1.4540e-03 eta 0:17:03
epoch [9/20] batch [300/592] time 0.142 (0.147) data 0.000 (0.002) loss 5.0877 (6.8621) cls_loss 0.3071 (1.4126) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.1023 (0.1874) contrast_loss 3.2854 (3.2734) lr 1.4540e-03 eta 0:16:40
epoch [9/20] batch [400/592] time 0.142 (0.147) data 0.000 (0.001) loss 5.1915 (6.8417) cls_loss 0.3121 (1.3997) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.1119 (0.1865) contrast_loss 3.3070 (3.2734) lr 1.4540e-03 eta 0:16:22
epoch [9/20] batch [500/592] time 0.142 (0.146) data 0.000 (0.001) loss 5.9173 (6.8874) cls_loss 0.9691 (1.4355) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.1231 (0.1872) contrast_loss 3.2865 (3.2775) lr 1.4540e-03 eta 0:16:05
epoch [10/20] batch [100/592] time 0.154 (0.149) data 0.000 (0.005) loss 6.6271 (6.4072) cls_loss 1.6318 (1.0554) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.1330 (0.1786) contrast_loss 3.2547 (3.2458) lr 1.3090e-03 eta 0:15:57
epoch [10/20] batch [200/592] time 0.142 (0.147) data 0.000 (0.002) loss 6.9325 (6.5103) cls_loss 0.8551 (1.1536) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.2547 (0.1784) contrast_loss 3.3630 (3.2522) lr 1.3090e-03 eta 0:15:26
epoch [10/20] batch [300/592] time 0.138 (0.146) data 0.000 (0.002) loss 7.4889 (6.5806) cls_loss 1.8934 (1.2066) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.2027 (0.1795) contrast_loss 3.2971 (3.2611) lr 1.3090e-03 eta 0:15:09
epoch [10/20] batch [400/592] time 0.144 (0.146) data 0.000 (0.001) loss 6.8173 (6.6445) cls_loss 0.7354 (1.2572) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.2653 (0.1807) contrast_loss 3.2823 (3.2646) lr 1.3090e-03 eta 0:14:53
epoch [10/20] batch [500/592] time 0.142 (0.146) data 0.000 (0.001) loss 6.0493 (6.6011) cls_loss 0.7874 (1.2286) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.1557 (0.1788) contrast_loss 3.3390 (3.2651) lr 1.3090e-03 eta 0:14:38
epoch [11/20] batch [100/592] time 0.140 (0.150) data 0.000 (0.004) loss 7.0552 (6.4865) cls_loss 1.4450 (1.1679) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.2217 (0.1734) contrast_loss 3.1599 (3.2547) lr 1.1564e-03 eta 0:14:32
epoch [11/20] batch [200/592] time 0.143 (0.148) data 0.000 (0.002) loss 6.0256 (6.4074) cls_loss 0.9236 (1.0890) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.1604 (0.1731) contrast_loss 3.1415 (3.2570) lr 1.1564e-03 eta 0:14:05
epoch [11/20] batch [300/592] time 0.153 (0.147) data 0.000 (0.002) loss 6.5630 (6.3983) cls_loss 1.0081 (1.0771) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.2136 (0.1732) contrast_loss 3.1692 (3.2583) lr 1.1564e-03 eta 0:13:43
epoch [11/20] batch [400/592] time 0.142 (0.147) data 0.000 (0.001) loss 6.7485 (6.3704) cls_loss 0.7356 (1.0564) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.2560 (0.1724) contrast_loss 3.2878 (3.2578) lr 1.1564e-03 eta 0:13:28
epoch [11/20] batch [500/592] time 0.142 (0.147) data 0.000 (0.001) loss 5.4393 (6.3624) cls_loss 0.6479 (1.0728) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.1145 (0.1694) contrast_loss 3.1982 (3.2572) lr 1.1564e-03 eta 0:13:14
epoch [12/20] batch [100/592] time 0.140 (0.150) data 0.000 (0.004) loss 6.8370 (6.2137) cls_loss 1.5789 (0.9458) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.1683 (0.1671) contrast_loss 3.2349 (3.2543) lr 1.0000e-03 eta 0:13:03
epoch [12/20] batch [200/592] time 0.149 (0.148) data 0.000 (0.002) loss 6.4785 (6.1016) cls_loss 1.1713 (0.8562) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.1687 (0.1649) contrast_loss 3.2806 (3.2490) lr 1.0000e-03 eta 0:12:36
epoch [12/20] batch [300/592] time 0.147 (0.147) data 0.000 (0.002) loss 5.3611 (6.1662) cls_loss 0.1491 (0.9306) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.1657 (0.1630) contrast_loss 3.2094 (3.2543) lr 1.0000e-03 eta 0:12:17
epoch [12/20] batch [400/592] time 0.142 (0.146) data 0.000 (0.001) loss 6.0338 (6.1077) cls_loss 0.8697 (0.8820) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.1465 (0.1618) contrast_loss 3.3154 (3.2541) lr 1.0000e-03 eta 0:12:01
epoch [12/20] batch [500/592] time 0.138 (0.146) data 0.000 (0.001) loss 5.3368 (6.1009) cls_loss 0.2992 (0.8903) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.1398 (0.1601) contrast_loss 3.2418 (3.2527) lr 1.0000e-03 eta 0:11:46
epoch [13/20] batch [100/592] time 0.142 (0.148) data 0.000 (0.005) loss 6.3766 (5.9958) cls_loss 0.7255 (0.8757) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.1974 (0.1492) contrast_loss 3.3946 (3.2497) lr 8.4357e-04 eta 0:11:24
epoch [13/20] batch [200/592] time 0.140 (0.146) data 0.000 (0.003) loss 5.0987 (5.9868) cls_loss 0.2432 (0.8720) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.1113 (0.1486) contrast_loss 3.2884 (3.2491) lr 8.4357e-04 eta 0:11:01
epoch [13/20] batch [300/592] time 0.142 (0.146) data 0.000 (0.002) loss 4.9061 (6.0528) cls_loss 0.1379 (0.9039) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.1141 (0.1529) contrast_loss 3.1787 (3.2487) lr 8.4357e-04 eta 0:10:45
epoch [13/20] batch [400/592] time 0.140 (0.145) data 0.000 (0.002) loss 5.0924 (5.9588) cls_loss 0.3851 (0.8226) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.1024 (0.1520) contrast_loss 3.2108 (3.2435) lr 8.4357e-04 eta 0:10:29
epoch [13/20] batch [500/592] time 0.141 (0.145) data 0.000 (0.001) loss 5.1236 (5.9426) cls_loss 0.1716 (0.8081) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.1292 (0.1520) contrast_loss 3.2412 (3.2414) lr 8.4357e-04 eta 0:10:14
epoch [14/20] batch [100/592] time 0.139 (0.149) data 0.000 (0.005) loss 5.1254 (5.9625) cls_loss 0.3803 (0.8070) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.1079 (0.1545) contrast_loss 3.2052 (3.2423) lr 6.9098e-04 eta 0:10:03
epoch [14/20] batch [200/592] time 0.141 (0.147) data 0.000 (0.003) loss 4.7643 (5.9200) cls_loss 0.1370 (0.8011) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.1049 (0.1500) contrast_loss 3.1108 (3.2418) lr 6.9098e-04 eta 0:09:39
epoch [14/20] batch [300/592] time 0.147 (0.146) data 0.000 (0.002) loss 6.4376 (5.7945) cls_loss 1.1599 (0.7068) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.1755 (0.1469) contrast_loss 3.1969 (3.2355) lr 6.9098e-04 eta 0:09:22
epoch [14/20] batch [400/592] time 0.140 (0.146) data 0.000 (0.002) loss 6.0152 (5.7578) cls_loss 0.8964 (0.6682) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.1492 (0.1477) contrast_loss 3.2479 (3.2311) lr 6.9098e-04 eta 0:09:05
epoch [14/20] batch [500/592] time 0.151 (0.146) data 0.000 (0.001) loss 6.7530 (5.7634) cls_loss 0.9050 (0.6730) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.2500 (0.1476) contrast_loss 3.1709 (3.2323) lr 6.9098e-04 eta 0:08:50
epoch [15/20] batch [100/592] time 0.149 (0.149) data 0.000 (0.004) loss 5.5806 (5.4997) cls_loss 0.1128 (0.5160) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.1838 (0.1350) contrast_loss 3.3208 (3.2268) lr 5.4601e-04 eta 0:08:34
epoch [15/20] batch [200/592] time 0.143 (0.147) data 0.000 (0.002) loss 4.9341 (5.6125) cls_loss 0.0803 (0.6097) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.1166 (0.1372) contrast_loss 3.2440 (3.2281) lr 5.4601e-04 eta 0:08:12
epoch [15/20] batch [300/592] time 0.144 (0.146) data 0.000 (0.002) loss 4.7616 (5.6219) cls_loss 0.0125 (0.5977) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.1148 (0.1400) contrast_loss 3.1537 (3.2273) lr 5.4601e-04 eta 0:07:56
epoch [15/20] batch [400/592] time 0.142 (0.146) data 0.000 (0.002) loss 4.8255 (5.6487) cls_loss 0.2340 (0.6177) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0875 (0.1409) contrast_loss 3.2143 (3.2266) lr 5.4601e-04 eta 0:07:40
epoch [15/20] batch [500/592] time 0.142 (0.146) data 0.000 (0.001) loss 4.5675 (5.6553) cls_loss 0.0481 (0.6306) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0808 (0.1401) contrast_loss 3.1965 (3.2266) lr 5.4601e-04 eta 0:07:24
epoch [16/20] batch [100/592] time 0.140 (0.149) data 0.000 (0.004) loss 5.0621 (5.6084) cls_loss 0.0440 (0.5979) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.1460 (0.1380) contrast_loss 3.1734 (3.2299) lr 4.1221e-04 eta 0:07:06
epoch [16/20] batch [200/592] time 0.151 (0.148) data 0.000 (0.003) loss 6.7758 (5.5161) cls_loss 1.0555 (0.5147) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.2215 (0.1379) contrast_loss 3.2718 (3.2214) lr 4.1221e-04 eta 0:06:47
epoch [16/20] batch [300/592] time 0.138 (0.147) data 0.000 (0.002) loss 4.6228 (5.4332) cls_loss 0.0311 (0.4646) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0865 (0.1345) contrast_loss 3.2223 (3.2158) lr 4.1221e-04 eta 0:06:30
epoch [16/20] batch [400/592] time 0.151 (0.146) data 0.000 (0.001) loss 6.6409 (5.4565) cls_loss 1.5859 (0.4868) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.1240 (0.1345) contrast_loss 3.3861 (3.2168) lr 4.1221e-04 eta 0:06:14
epoch [16/20] batch [500/592] time 0.147 (0.146) data 0.000 (0.001) loss 6.3001 (5.5028) cls_loss 1.4080 (0.5207) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.1201 (0.1354) contrast_loss 3.2541 (3.2223) lr 4.1221e-04 eta 0:05:59
epoch [17/20] batch [100/592] time 0.147 (0.151) data 0.000 (0.004) loss 4.5243 (5.3063) cls_loss 0.0883 (0.3955) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0665 (0.1279) contrast_loss 3.2267 (3.2103) lr 2.9289e-04 eta 0:05:42
epoch [17/20] batch [200/592] time 0.147 (0.148) data 0.000 (0.002) loss 4.8165 (5.2971) cls_loss 0.1492 (0.3826) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0982 (0.1292) contrast_loss 3.2051 (3.2042) lr 2.9289e-04 eta 0:05:21
epoch [17/20] batch [300/592] time 0.144 (0.147) data 0.000 (0.002) loss 4.7589 (5.3287) cls_loss 0.2535 (0.4303) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0720 (0.1264) contrast_loss 3.2522 (3.2105) lr 2.9289e-04 eta 0:05:04
epoch [17/20] batch [400/592] time 0.151 (0.146) data 0.000 (0.001) loss 5.1455 (5.3420) cls_loss 0.3170 (0.4337) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.1226 (0.1275) contrast_loss 3.1706 (3.2113) lr 2.9289e-04 eta 0:04:48
epoch [17/20] batch [500/592] time 0.147 (0.146) data 0.000 (0.001) loss 4.8444 (5.3362) cls_loss 0.2470 (0.4317) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0859 (0.1270) contrast_loss 3.2330 (3.2112) lr 2.9289e-04 eta 0:04:33
epoch [18/20] batch [100/592] time 0.147 (0.150) data 0.000 (0.005) loss 5.5364 (5.3957) cls_loss 0.3696 (0.5205) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.1695 (0.1236) contrast_loss 3.1338 (3.2096) lr 1.9098e-04 eta 0:04:11
epoch [18/20] batch [200/592] time 0.149 (0.148) data 0.000 (0.003) loss 5.2315 (5.3927) cls_loss 0.4686 (0.4831) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.1165 (0.1270) contrast_loss 3.1543 (3.2165) lr 1.9098e-04 eta 0:03:52
epoch [18/20] batch [300/592] time 0.142 (0.147) data 0.000 (0.002) loss 5.2593 (5.3744) cls_loss 0.0690 (0.4708) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.1797 (0.1264) contrast_loss 3.0754 (3.2153) lr 1.9098e-04 eta 0:03:36
epoch [18/20] batch [400/592] time 0.149 (0.146) data 0.000 (0.002) loss 4.8539 (5.3465) cls_loss 0.3239 (0.4554) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0839 (0.1252) contrast_loss 3.1821 (3.2127) lr 1.9098e-04 eta 0:03:21
epoch [18/20] batch [500/592] time 0.142 (0.146) data 0.000 (0.001) loss 4.5290 (5.3034) cls_loss 0.0193 (0.4305) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0777 (0.1229) contrast_loss 3.2113 (3.2127) lr 1.9098e-04 eta 0:03:06
epoch [19/20] batch [100/592] time 0.148 (0.148) data 0.000 (0.004) loss 4.7862 (5.0800) cls_loss 0.0302 (0.2384) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.1120 (0.1208) contrast_loss 3.1829 (3.1979) lr 1.0899e-04 eta 0:02:40
epoch [19/20] batch [200/592] time 0.142 (0.147) data 0.000 (0.002) loss 4.5653 (5.2290) cls_loss 0.0197 (0.3659) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0793 (0.1233) contrast_loss 3.2342 (3.2001) lr 1.0899e-04 eta 0:02:24
epoch [19/20] batch [300/592] time 0.147 (0.146) data 0.000 (0.002) loss 4.5804 (5.1907) cls_loss 0.0211 (0.3482) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0781 (0.1204) contrast_loss 3.2573 (3.2022) lr 1.0899e-04 eta 0:02:09
epoch [19/20] batch [400/592] time 0.146 (0.146) data 0.000 (0.001) loss 4.9336 (5.2121) cls_loss 0.1872 (0.3622) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.1128 (0.1212) contrast_loss 3.1672 (3.2035) lr 1.0899e-04 eta 0:01:54
epoch [19/20] batch [500/592] time 0.140 (0.146) data 0.000 (0.001) loss 5.0688 (5.1940) cls_loss 0.2113 (0.3559) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.1296 (0.1198) contrast_loss 3.1437 (3.2028) lr 1.0899e-04 eta 0:01:39
epoch [20/20] batch [100/592] time 0.143 (0.150) data 0.000 (0.006) loss 4.8597 (5.1848) cls_loss 0.3644 (0.3521) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0733 (0.1185) contrast_loss 3.2317 (3.2081) lr 4.8943e-05 eta 0:01:13
epoch [20/20] batch [200/592] time 0.153 (0.147) data 0.000 (0.003) loss 4.6467 (5.1879) cls_loss 0.1545 (0.3547) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0687 (0.1180) contrast_loss 3.2656 (3.2125) lr 4.8943e-05 eta 0:00:57
epoch [20/20] batch [300/592] time 0.143 (0.146) data 0.000 (0.002) loss 4.8271 (5.1504) cls_loss 0.2297 (0.3242) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0771 (0.1174) contrast_loss 3.3034 (3.2104) lr 4.8943e-05 eta 0:00:42
epoch [20/20] batch [400/592] time 0.146 (0.146) data 0.000 (0.002) loss 4.5643 (5.1667) cls_loss 0.0715 (0.3424) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.0892 (0.1174) contrast_loss 3.1026 (3.2084) lr 4.8943e-05 eta 0:00:27
epoch [20/20] batch [500/592] time 0.142 (0.146) data 0.000 (0.002) loss 4.8331 (5.1800) cls_loss 0.1601 (0.3481) prompt_loss 0.6770 (0.6770) kgcoop_loss 0.1053 (0.1187) contrast_loss 3.1535 (3.2057) lr 4.8943e-05 eta 0:00:13
Checkpoint saved to /oxford_pets/vit_b16_cepl_16shots/seed2/efficient_prompt/model.pth.tar-20
Finish training
Deploy the last-epoch model
Evaluate on the *test* set
=> result
* total: 3,669
* correct: 3,421
* accuracy: 93.241%
* error: 6.759%
* macro_f1: 93.114%
Elapsed: 1:01:10
